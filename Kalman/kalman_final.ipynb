{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KalmanFilter(object):\n",
    "    def __init__(self, dt, u_x,u_y, std_acc, x_std_meas, y_std_meas):\n",
    "        \n",
    "        #x_std_meas ans y_std_meas are standard diviation about x and y axis\n",
    "\n",
    "        self.dt = dt\n",
    "\n",
    "        #Input variables in 2D  \n",
    "        self.u = np.matrix([[u_x],[u_y]])\n",
    "\n",
    "        ### Initialisation ###\n",
    "        self.x = np.matrix([[0], [0], [0], [0]])\n",
    "\n",
    "        self.F = np.matrix([[1, 0, self.dt, 0],\n",
    "                            [0, 1, 0, self.dt],\n",
    "                            [0, 0, 1, 0],\n",
    "                            [0, 0, 0, 1]])\n",
    "\n",
    "        \n",
    "        self.G = np.matrix([[(self.dt**2)/2, 0],\n",
    "                            [0,(self.dt**2)/2],\n",
    "                            [self.dt,0],\n",
    "                            [0,self.dt]])\n",
    "\n",
    "        \n",
    "        self.H = np.matrix([[1, 0, 0, 0],\n",
    "                            [0, 1, 0, 0]])\n",
    "\n",
    "\n",
    "        self.Q = np.matrix([[(self.dt**4)/4, 0, (self.dt**3)/2, 0],\n",
    "                            [0, (self.dt**4)/4, 0, (self.dt**3)/2],\n",
    "                            [(self.dt**3)/2, 0, self.dt**2, 0],\n",
    "                            [0, (self.dt**3)/2, 0, self.dt**2]]) * std_acc**2\n",
    "\n",
    "\n",
    "        self.R = np.matrix([[x_std_meas**2,0],\n",
    "                           [0, y_std_meas**2]])\n",
    "\n",
    "        \n",
    "        self.P = np.eye(self.F.shape[1])\n",
    "\n",
    "    def predict(self):\n",
    "     \n",
    "        self.x = np.dot(self.F, self.x) + np.dot(self.G, self.u)\n",
    "        \n",
    "        self.P = np.dot(np.dot(self.F, self.P), self.F.T) + self.Q\n",
    "        \n",
    "        return self.x[0:2]\n",
    "\n",
    "    def update(self, z):\n",
    "\n",
    "        S = np.dot(self.H, np.dot(self.P, self.H.T)) + self.R\n",
    "\n",
    "        K = np.dot(np.dot(self.P, self.H.T), np.linalg.inv(S))  \n",
    "\n",
    "        self.x = np.round(self.x + np.dot(K, (z - np.dot(self.H, self.x))))   \n",
    "\n",
    "        I = np.eye(self.H.shape[1])\n",
    "\n",
    "        self.P = (I - (K * self.H)) * self.P\n",
    "        \n",
    "        return self.x[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(frame,debugMode):\n",
    "    \n",
    "    #Convert to grayscale image\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    if (debugMode):\n",
    "        cv2.imshow('gray', gray)\n",
    "\n",
    "    #Edge detection of object\n",
    "    img_edges = cv2.Canny(gray,  50, 190, 3)\n",
    "    if (debugMode):\n",
    "        cv2.imshow('img_edges', img_edges)\n",
    "\n",
    "    # Convert to binary image\n",
    "    ret, img_thresh = cv2.threshold(img_edges, 254, 255,cv2.THRESH_BINARY)\n",
    "    if (debugMode):\n",
    "        cv2.imshow('img_thresh', img_thresh)\n",
    "\n",
    "    #Find contours\n",
    "    contours, _ = cv2.findContours(img_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    min_radius_thresh= 3\n",
    "    max_radius_thresh= 30\n",
    "\n",
    "    centers=[]\n",
    "    for c in contours:\n",
    "       \n",
    "        (x, y), radius = cv2.minEnclosingCircle(c)\n",
    "        radius = int(radius)\n",
    "\n",
    "        if (radius > min_radius_thresh) and (radius < max_radius_thresh):\n",
    "            centers.append(np.array([[x], [y]]))\n",
    "    cv2.imshow('contours', img_thresh)\n",
    "    return centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.0.1) C:\\ci\\opencv-suite_1573470242804\\work\\modules\\imgproc\\src\\color.cpp:181: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7127aa2c71eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-7127aa2c71eb>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVideoCap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mcenters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdebugMode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcenters\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-87292278c490>\u001b[0m in \u001b[0;36mdetect\u001b[1;34m(frame, debugMode)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m#Convert to grayscale image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_RGB2BGR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdebugMode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.0.1) C:\\ci\\opencv-suite_1573470242804\\work\\modules\\imgproc\\src\\color.cpp:181: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    #Create opencv video capture object\n",
    "    VideoCap = cv2.VideoCapture('OneBall.avi')\n",
    "    #print(VideoCap)\n",
    "\n",
    "   \n",
    "    ControlSpeedVar = 100  \n",
    "    HiSpeed = 100\n",
    "    \n",
    "    frame_width = int(VideoCap.get(3))\n",
    "    frame_height = int(VideoCap.get(4))\n",
    "   \n",
    "    size = (frame_width, frame_height)\n",
    "    \n",
    "    result = cv2.VideoWriter('output_ball.avi', cv2.VideoWriter_fourcc(*'MJPG'), 10, size)\n",
    "\n",
    "###Attention\n",
    "    KF = KalmanFilter(0.1, 1, 1, 1, 0.1,0.1)\n",
    "###Attention\n",
    "\n",
    "    debugMode=1\n",
    "\n",
    "    while(True):\n",
    "        # Read frame\n",
    "        ret, frame = VideoCap.read()\n",
    "\n",
    "        centers = detect(frame,debugMode)\n",
    "\n",
    "        if (len(centers) > 0):\n",
    "            \n",
    "####Attention\n",
    "            # Predict\n",
    "            (x, y) = KF.predict()\n",
    "            # Update\n",
    "            #Input and Output coordinates are to be fed and fetched from here\n",
    "            (x1, y1) = KF.update(centers[0]) #Input coordinates centers[0], Estimated output position coordinates (x1, y1)\n",
    "####Attention\n",
    "\n",
    "            #Mark the estimated position in the video\n",
    "            cv2.rectangle(frame, (int(x1 - 15), int(y1 - 15)), (int(x1 + 15), int(y1 + 15)), (0, 0, 255), 2)\n",
    "\n",
    "        result.write(frame)\n",
    "        cv2.imshow('image', frame)\n",
    "        \n",
    "\n",
    "        if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "            VideoCap.release()\n",
    "            result.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "        cv2.waitKey(HiSpeed-ControlSpeedVar+1)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
